{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ContentDM ARK Assignment\n",
    "Created by Ryan Wolfslayer, 2018, Iowa State University.\n",
    "\n",
    "Maintained by Wesley Teal, 2019, Iowa State University."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob \n",
    "import gzip\n",
    "from io import StringIO\n",
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "from lxml import etree\n",
    "from lxml.etree import parse\n",
    "\n",
    "import arks_code.download_cdm as cdm \n",
    "import arks_code.transformations as trans\n",
    "from batch_download import batch_download\n",
    "\n",
    "TARGETPATH = os.path.join(os.getcwd(),'cdm_xml')\n",
    "\n",
    "# CONFIGURATION VARIABLES ===============================\n",
    "# Change the following variables to suit your need.\n",
    "\n",
    "# Enter login information for EZID\n",
    "ezid_username = \"\"\n",
    "ezid_password = \"\"\n",
    "\n",
    "# Enter the ARK shoulder you'll be using.\n",
    "ezid_shoulder = \"\"\n",
    "\n",
    "# declare collection number to upload, i.e. p16001coll47\n",
    "collection_number = \"\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 (Optional): Download XML from CDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# OPTIONAL STEP\n",
    "\n",
    "ff = cdm.DownloadXML()\n",
    "ff.setup(TARGETPATH, driver_path='arks_code/chromedriver')\n",
    "\n",
    "ff.driver.close()\n",
    "\n",
    "# rename files\n",
    "for file in glob.glob(TARGETPATH+'/export*.xml'):\n",
    "    root = etree.parse(file).xpath('//rdf:Description/@about', \n",
    "                                   namespaces={'rdf':\n",
    "                                               \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"})\n",
    "    try:\n",
    "        shutil.move(file, \n",
    "                    os.path.join(TARGETPATH, \n",
    "                                 str(root[0].split('/')[-3])+'.xml'))\n",
    "    except IndexError:\n",
    "        # If we can't get the name because the URL differs from the standard,\n",
    "        # just move on to the next iteration of the loop and rename all the files\n",
    "        # we can.\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Select Collection and convert to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! This section is currently unstable and may be subject to major changes.\n",
    "# There seem to be new issues that crop up from time to time here that halt\n",
    "# processing dead.\n",
    "\n",
    "collection_filename = f\"{TARGETPATH}/{collection_number}.xml\"\n",
    "\n",
    "with open(collection_filename, \"r\", encoding=\"utf-8\") as fh:\n",
    "    in_file = fh.read()\n",
    "    \n",
    "# Was getting a 404 error when attempting to resolve the Dublin Core namespace,\n",
    "# so stripping out namespaces for now to get XPath queries to work. This is \n",
    "# perhaps not ideal and may not be permanantly needed. If this does become\n",
    "# permanent, it should be moved into its own function.\n",
    "in_file = in_file.replace('<rdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\\n', '<RDF>')\n",
    "in_file = in_file.replace('         xmlns:dc=\"http://purl.org/dc/elements/1.1/\">\\n', '')\n",
    "in_file = in_file.replace('dc:', '')\n",
    "in_file = in_file.replace('rdf:', '')\n",
    "\n",
    "tree = etree.parse(StringIO(in_file))\n",
    "\n",
    "# This should probably be moved into its own function if it seems\n",
    "# like a long-term solution.\n",
    "metadata = {}\n",
    "metadata[\"url\"] = tree.xpath(\"//Description/@about\")\n",
    "metadata[\"title\"] = [e.text for e in tree.xpath(\"//title\")]\n",
    "metadata[\"date\"] = [e.text for e in tree.xpath(\"//date\")]\n",
    "metadata[\"type\"] = [e.text for e in tree.xpath(\"//type\")]\n",
    "metadata[\"creator\"] = [e.text for e in tree.xpath(\"//creator\")]\n",
    "\n",
    "df = pd.DataFrame.from_dict(metadata)\n",
    "\n",
    "df = df.iloc[1:]\n",
    "df['publisher'] = 'Iowa State University Library'\n",
    "\n",
    "# We DO NOT want to create ARKs for each individual part of an object\n",
    "# just the object as a whole, so we need to filter out items whose titles\n",
    "# are Page #, p. #, Front, and Back, or those with no title.\n",
    "df = df[~df.title.str.match(\"(^([Pp](age|\\.) \\d+|[Ff]ront|[Bb]ack)$|^$)\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Confirm collection metadata is accurate, and make corrections. \n",
    "Note that this step is subject to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count is incorrect, removing undated rows \n",
    "#df = df[df['date']!='undated']\n",
    "df.shape\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGISTER EZID; this will submit to EZID\n",
    "# Requires ezid.py be stored in same directory.\n",
    "#### !!! Change this back to `df.iterrows` !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "for index, row in leftovers.iterrows():\n",
    "    with open(\"metadata.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write('erc.who:{}\\n'.format(row['creator']))\n",
    "        f.write('erc.what:{}\\n'.format(row['title']))\n",
    "        f.write('erc.when:{}\\n'.format(row['date']))\n",
    "        \n",
    "        if row['creator'] != None and str(row['creator']) != 'nan':\n",
    "            f.write('dc.creator:{}\\n'.format(row['creator']))\n",
    "        else:\n",
    "            pass\n",
    "        f.write('dc.title:{}\\n'.format(row['title']))\n",
    "        f.write('dc.publisher:{}\\n'.format(row['publisher']))\n",
    "        if row['date'] != None and str(row['date']) != 'nan':\n",
    "            f.write('dc.date:{}\\n'.format(row['date']))\n",
    "        else:\n",
    "            pass\n",
    "        if row['type'] != None and str(row['type']) != 'nan':\n",
    "            f.write('dc.type:{}\\n'.format(row['type']))\n",
    "        else:\n",
    "            pass\n",
    "        f.write('_target:{}\\n'.format(row['url']))\n",
    "        f.write('_profile:dc')\n",
    "    result = subprocess.run([\"python\", \"ezid.py\", \"{}:{}\".format(ezid_username, ezid_password), \"mint\", ezid_shoulder, \"@\", \"metadata.txt\"],\n",
    "                   capture_output=True, \n",
    "                   shell=True,\n",
    "                   encoding=\"utf-8\")\n",
    "    print(row['title'])\n",
    "    print(f\"STDOUT: {result.stdout}\\nSTDERR: {result.stderr}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_download(ezid_username, ezid_password, [\"format=xml\", \"type=ark\"])\n",
    "\n",
    "# MAKE SURE there are no gzipped files in the ark directory\n",
    "# prior to running batch_download or this might grab the wrong\n",
    "# file.\n",
    "gzipped_file = next(x for x in os.listdir(\".\") if x.endswith(\".xml.gz\"))\n",
    "output_dir = \"ezid_xml\"\n",
    "target_xml = os.path.join(output_dir, gzipped_file[:-3])\n",
    "\n",
    "with gzip.open(gzipped_file, \"rt\", encoding=\"utf-8\") as ifh:\n",
    "    with open(target_xml, \"w\", encoding=\"utf-8\") as ofh:\n",
    "        ofh.write(ifh.read())\n",
    "\n",
    "# Once we've unzipped the file into the ezid_xml directory,\n",
    "# we can delete the downloaded file.\n",
    "os.remove(gzipped_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTENTdm Upload Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Identify target URLs and format as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = trans.formatupload(collection_number)(parse(target_xml))\n",
    "my_dict = ast.literal_eval(str(trans.formatxmltodict()(root)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Make sure urls are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x.text for x in root.xpath('record/element[@name=\"_target\"]')]\n",
    "print(len(my_dict))\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Upload to CONTENTdm with Selenium\n",
    "You may need to change the following:\n",
    "* CONTENTdm server\n",
    "* Driver path\n",
    "* Sign in with CONTENTdm credentials when prompted\n",
    "* Collection name value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "driver = webdriver.Chrome(r'arks_code/chromedriver')\n",
    "driver.get('https://server16001.contentdm.oclc.org/cgi-bin/admin/start.exe')\n",
    "\n",
    "collections_tab = driver.find_element(By.XPATH, \"//a[@id='acolls' and @title='collections']\")\n",
    "collections_tab.click()\n",
    "\n",
    "driver.implicitly_wait(10)\n",
    "driver.maximize_window()\n",
    "element = driver.find_element(By.XPATH, '//select[@name=\"CISODB\"]')\n",
    "sel = Select(element)\n",
    "sel.select_by_value('/{}'.format(collection_number.replace('/','')))\n",
    "\n",
    "driver.find_element(By.XPATH, '//input[@type=\"submit\" and @value=\"change\"]').click()\n",
    "\n",
    "items_tab = driver.find_element(By.XPATH, \"//a[@id='aitems' and @title='items']\")\n",
    "items_tab.click()\n",
    "\n",
    "edit_collection = driver.find_element(By.XPATH, '//a/b[text()=\"Edit\"]')\n",
    "edit_collection.click()\n",
    "driver.find_element(By.XPATH, '//*[@id=\"AllFields\"]/div/table/tbody/tr[1]/td[3]/span/a/b').click()\n",
    "\n",
    "num = int(driver.find_element(By.XPATH, '/html/body/table/tbody/tr[2]/td/table/tbody/tr/td/table[2]/tbody/tr[1]/td/span/b/span' ).text)\n",
    "table_range = num // 50\n",
    "\n",
    "# Table Data\n",
    "x = driver.find_elements(By.XPATH, '//table[@summary=\"search results\"]/tbody/tr/td/span/a[1]')\n",
    "urllist = [y.get_attribute(\"href\") for y in x]\n",
    "\n",
    "if table_range < 1:\n",
    "    pass\n",
    "else:\n",
    "    for x in range(table_range):\n",
    "        driver.find_elements(By.XPATH, '//a[@title=\"Next page\"]')[0].click()\n",
    "        x = driver.find_elements(By.XPATH, '//table[@summary=\"search results\"]/tbody/tr/td/span/a[1]')\n",
    "        [urllist.append(y.get_attribute(\"href\")) for y in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Make sure the urllist/2 and my_dict are equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The length of urllist is roughly (but not always exactly)\n",
    "# double the length of my_dict because for each url that\n",
    "# corresponds to the url in my_dict there is often an additional\n",
    "# one that includes \"edittxt.exe.\" If we remove this second\n",
    "# type of url, we get a better number for comparison.\n",
    "urllist_len = len([x for x in urllist if \"edittxt.exe\" not in x])\n",
    "my_dict_len = len(my_dict)\n",
    "\n",
    "print(urllist_len == my_dict_len)\n",
    "print(urllist_len)\n",
    "print(my_dict_len)\n",
    "#print(urllist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9: Upload ARKS to CONTENTdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# iterate through every other url and update identifier AllFields\n",
    "for item in urllist:\n",
    "    print(item)\n",
    "    if 'cdm16001' in item:\n",
    "            pass\n",
    "    else:\n",
    "        driver.get(item)\n",
    "        # send Ark if title matches ?\n",
    "        urlfind = driver.find_element(By.XPATH, '/html/body/table/tbody/tr[2]/td/table/tbody/tr/td/table[2]/tbody/tr[2]/td/table/tbody/tr[1]/td/span/a')\n",
    "        z = urlfind.get_attribute('href')\n",
    "        z = z.split('/')\n",
    "        z[4] = 'ref'\n",
    "        z = '/'.join(z)\n",
    "        \n",
    "        # pick only one\n",
    "        #----------------------------------------------------------------------------------------\n",
    "        #identifier_field = driver.find_element(By.XPATH, '//input[@name=\"id\"]')\n",
    "        #identifier_field = driver.find_element(By.XPATH, '//input[@name=\"identi\"]')\n",
    "        # identifier_field = driver.find_element(By.XPATH, '//input[@name=\"identa\"]')\n",
    "        # identifier_field = driver.find_element(By.XPATH, '/html/body/table/tbody/tr[2]/td/table/tbody/tr/td/table[2]/tbody/tr[2]/td/table/tbody/tr[28]/td[2]/input')\n",
    "        identifier_field = driver.find_element(By.XPATH, '//input[@name=\"uid\"]')\n",
    "        \n",
    "        \n",
    "        #----------------------------------------------------------------------------------------\n",
    "        identifier_field_value = identifier_field.get_attribute('value')\n",
    "        if identifier_field_value == '':\n",
    "            try:\n",
    "                identifier_field.send_keys('{}{}'.format('https://n2t.net/',my_dict[(z[16:].split(',')[0].replace(\"'\",''))]))\n",
    "    \n",
    "                # time.sleep(10)\n",
    "                #--------------------------------------------------------------------\n",
    "                driver.find_element(By.XPATH, '//input[@id=\"subbut\"]').click()\n",
    "                #--------------------------------------------------------------------\n",
    "            except KeyError:\n",
    "                print('Error on {}'.format(z))\n",
    "        \n",
    "        else:\n",
    "            try:\n",
    "                if \"https://n2t.net/ark:/87292/\" not in identifier_field_value:\n",
    "                    identifier_field.send_keys('; {}{}'.format('https://n2t.net/',my_dict[(z[16:].split(',')[0].replace(\"'\",''))]))\n",
    "                \n",
    "                if \";\" in identifier_field_value:\n",
    "                    set_key = '<br>'.join(set(identifier_field.get_attribute('value').strip().split('; ')))\n",
    "                    identifier_field.clear()\n",
    "                    identifier_field = driver.find_element(By.XPATH, '//input[@name=\"identi\"]')\n",
    "                    # identifier_field = driver.find_element(By.XPATH, '//input[@name=\"uid\"]')\n",
    "                    # identifier_field = driver.find_element(By.XPATH, '/html/body/table/tbody/tr[2]/td/table/tbody/tr/td/table[2]/tbody/tr[2]/td/table/tbody/tr[28]/td[2]/input')\n",
    "                    identifier_field.send_keys(set_key)\n",
    "                #--------------------------------------------------------------------\n",
    "                driver.find_element(By.XPATH, '//input[@id=\"subbut\"]').click()\n",
    "                #--------------------------------------------------------------------\n",
    "                # time.sleep(10)\n",
    "            except KeyError:\n",
    "                print('Error on {}'.format(z))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arks_code import report\n",
    "\n",
    "info = report.generate_tsv(\"ezid_xml/d96217d52b.xml\")\n",
    "report.write_tsv(info, \"arks_report.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
